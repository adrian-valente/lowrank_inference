"""
August 2021.

Trying out different methods for fitting low-rank networks to data generated by a full-rank network performing Mante task.

02/03/22 modified to fit only after contextual onset
"""

import sys
sys.path.append('../')

from low_rank_rnns.modules import *
from low_rank_rnns import mante, stats

size = 512
noise_std = 3e-2
alpha = .2
n_epochs = 50

x_train, y_train, mask_train, x_val, y_val, mask_val = mante.generate_mante_data(1000)
net = LowRankRNN(4, size, 1, noise_std, alpha, rank=1)

net.load_state_dict(torch.load(f'../models/mante_rank1_{size}.pt', map_location='cpu'))
loss, acc = mante.test_mante(net, x_val, y_val, mask_val)
print(f'loss={loss:.3f}, acc={acc:.3f}')

output, traj = net.forward(x_train, return_dynamics=True)
T = x_train.shape[1]
target = torch.tanh(traj[:, 1:].detach())
mask = torch.ones((x_train.shape[0], T, 1))

# Fitting a rank r network
net2 = LowRankRNN(4, size, size, noise_std, alpha, rank=1,
                  wo_init=size * torch.from_numpy(np.eye(size)), train_wi=True, train_so=False)

train(net2, x_train, target, mask, n_epochs, lr=1e-2, clip_gradient=1, keep_best=True, cuda=True)
net2.to('cpu')
torch.save(net2.state_dict(), f'../models/mante_fitlr_{size}.pt')
out1, traj1 = net.forward(x_val, return_dynamics=True)
out2, traj2 = net2.forward(x_val, return_dynamics=True)
traj1 = net.non_linearity(traj1)
traj2 = net2.non_linearity(traj2)
y1 = traj1.detach().numpy().ravel()
y2 = traj2.detach().numpy().ravel()
r2 = stats.r2_score(y1, y2)
print(r2)